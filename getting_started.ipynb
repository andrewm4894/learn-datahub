{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from dotenv import load_dotenv\n",
    "from typing import List\n",
    "from datahub.emitter.mcp import MetadataChangeProposalWrapper\n",
    "import datahub.metadata.schema_classes as models\n",
    "import datahub.emitter.mce_builder as builder\n",
    "from datahub.emitter.rest_emitter import DatahubRestEmitter\n",
    "load_dotenv()\n",
    "\n",
    "# replace .env_example with a file called .env and add your own environment variables into it.\n",
    "datashub_gms_server = os.getenv('DATAHUB_GMS_SERVER', '')\n",
    "datahub_token = os.getenv('DATAHUB_TOKEN', '')\n",
    "datahub_actor = os.getenv('DATAHUB_ACTOR', 'urn:li:corpuser:admin')\n",
    "\n",
    "# start by putting things into DEV to keep PROD clean until you know what you are doing\n",
    "datahub_env = 'DEV'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create emitter\n",
    "\n",
    "We must first create a `DatahubRestEmitter` object we will use to emit our `MetadataChangeProposalWrapper` change proposals to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an emitter\n",
    "emitter = DatahubRestEmitter(\n",
    "    gms_server=datashub_gms_server, \n",
    "    token=datahub_token, \n",
    "    extra_headers={'X-DataHub-Actor': datahub_actor}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some tags\n",
    "\n",
    "Lets define a dictionary of tags with some key and values defined for each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some tags\n",
    "tags = {\n",
    "    'healthy': {'description': 'This resource is healthy'}, \n",
    "    'failing': {'description': 'This resource is failing'},\n",
    "    'production': {'description': 'This resource is considered production grade'},\n",
    "    'dev': {'description': 'This resource is considered development grade'},\n",
    "    }\n",
    "\n",
    "# create each tag\n",
    "for tag in tags:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"tag\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_tag_urn(tag),\n",
    "        aspectName=\"tagProperties\",\n",
    "        aspect=models.TagPropertiesClass(\n",
    "            name=tag, \n",
    "            description=tags[tag].get('description')\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![tags](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/tags.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some glossary terms\n",
    "\n",
    "Lets create some glossary terms we can associate with various entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some glossary terms\n",
    "\n",
    "glossary_terms = {\n",
    "    'active user': {'definition': 'A user who has logged in in last 30d.', 'source': 'INTERNEAL'},\n",
    "    'inactive user': {'definition': 'A user who has not logged in in last 90d.', 'source': 'INTERNEAL'},\n",
    "}\n",
    "\n",
    "# create each term\n",
    "for glossary_term in glossary_terms:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"glossaryTerm\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=f'urn:li:glossaryTerm:{glossary_term}',\n",
    "        aspectName=\"glossaryTermInfo\",\n",
    "        aspect=models.GlossaryTermInfoClass(\n",
    "            definition=glossary_terms[glossary_term].get('definition'), \n",
    "            termSource=glossary_terms[glossary_term].get('source')\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![glossary_terms](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/glossary_terms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some users\n",
    "\n",
    "users = {\n",
    "    'Joe Bloggs': {'display_name': 'Joe Bloggs', 'email': 'joe.bloggs@fake.com', 'active': True},\n",
    "    'Dummy User': {'display_name': 'Dummy User', 'email': 'dummy.user@fake.com', 'active': True},\n",
    "}\n",
    "\n",
    "# create each user\n",
    "for user in users:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"corpUser\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_user_urn(username=user),\n",
    "        aspectName=\"corpUserInfo\",\n",
    "        aspect=models.CorpUserInfoClass(\n",
    "            displayName=users[user].get('display_name'), \n",
    "            email=users[user].get('email'),\n",
    "            active=users[user].get('active')\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![user](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/user.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some dataset's\n",
    "\n",
    "Lets create 3 datasets that we will manually string together via upstream lineages later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some datasets\n",
    "dataset_platform = 'bigquery'\n",
    "\n",
    "# note: we will add some attributes like 'tags' to use later.\n",
    "\n",
    "datasets = {\n",
    "    'project_a.dataset_a.table_1' : {\n",
    "        'description': 'my great dataset 1', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dataset_platform, \n",
    "        'env': datahub_env, \n",
    "        'tags': ['healthy', 'production'],\n",
    "        'owners': ['Joe Bloggs', 'Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'upstream datasets': []\n",
    "        },\n",
    "    'project_a.dataset_a.table_2' : {\n",
    "        'description': 'my great dataset 2', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dataset_platform, \n",
    "        'env': datahub_env, \n",
    "        'tags': ['failing', 'dev'],\n",
    "        'owners': ['Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'upstream datasets': ['project_a.dataset_a.table_1']\n",
    "        },\n",
    "    'project_a.dataset_a.table_3' : {\n",
    "        'description': 'my great dataset 3', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dataset_platform, \n",
    "        'env': datahub_env, \n",
    "        'tags': ['failing', 'production'],\n",
    "        'owners': ['Joe Bloggs'],\n",
    "        'glossary terms': ['inactive user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'upstream datasets': ['project_a.dataset_a.table_2']\n",
    "        },\n",
    "}\n",
    "\n",
    "# make each dataset\n",
    "for dataset in datasets:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"datasetProperties\",\n",
    "        aspect=models.DatasetPropertiesClass(\n",
    "            description=datasets[dataset].get('description'), \n",
    "            externalUrl=datasets[dataset].get('url')\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some charts\n",
    "chart_platform = 'datastudio'\n",
    "\n",
    "# note: we will add some attributes like 'tags' to use later.\n",
    "\n",
    "charts = {\n",
    "    'chart_1' : {\n",
    "        'title': 'chart 1',\n",
    "        'description': 'lovely chart 1', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': chart_platform, \n",
    "        'tags': ['healthy', 'production'],\n",
    "        'owners': ['Joe Bloggs', 'Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'inputs': ['project_a.dataset_a.table_1']\n",
    "        },\n",
    "    'chart_2' : {\n",
    "        'title': 'chart 2',\n",
    "        'description': 'my great chart 2', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': chart_platform, \n",
    "        'tags': ['failing', 'dev'],\n",
    "        'owners': ['Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'inputs': ['project_a.dataset_a.table_2']\n",
    "        },\n",
    "    'chart_3' : {\n",
    "        'title': 'chart 3',\n",
    "        'description': 'my great chart 3', \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': chart_platform, \n",
    "        'tags': ['failing', 'production'],\n",
    "        'owners': ['Joe Bloggs'],\n",
    "        'glossary terms': ['inactive user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'},\n",
    "        'inputs': ['project_a.dataset_a.table_3']\n",
    "        },\n",
    "}\n",
    "\n",
    "# make each chart\n",
    "for chart in charts:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"chart\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_chart_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=chart\n",
    "        ),\n",
    "        aspectName=\"chartInfo\",\n",
    "        aspect=models.ChartInfoClass(\n",
    "            title=charts[chart].get('title'),\n",
    "            description=charts[chart].get('description'), \n",
    "            lastModified=models.ChangeAuditStampsClass(\n",
    "                created=models.AuditStampClass(\n",
    "                    time=int(time.time()),\n",
    "                    actor=datahub_actor\n",
    "                )\n",
    "            ),\n",
    "            inputs=[\n",
    "                builder.make_dataset_urn(\n",
    "                    platform=datasets[input].get('platform'), \n",
    "                    name=input, \n",
    "                    env=datasets[input].get('env')\n",
    "                    )\n",
    "                for input in charts[chart].get('inputs',[])\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![charts](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/charts.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_chart_dashboard_lineage](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_chart_dashboard_lineage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create some dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create some dashboards\n",
    "dashboard_platform = 'datastudio'\n",
    "\n",
    "# note: we will add some attributes like 'tags' to use later.\n",
    "\n",
    "dashboards = {\n",
    "    'dashboard_1' : {\n",
    "        'title': 'dashboard 1',\n",
    "        'description': 'lovely dashboard 1',\n",
    "        'charts': ['chart_1'],\n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dashboard_platform, \n",
    "        'tags': ['healthy', 'production'],\n",
    "        'owners': ['Joe Bloggs', 'Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'}\n",
    "        },\n",
    "    'dashboard_2' : {\n",
    "        'title': 'dashboard 2',\n",
    "        'description': 'my great dashboard 2',\n",
    "        'charts': ['chart_2'], \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dashboard_platform, \n",
    "        'tags': ['failing', 'dev'],\n",
    "        'owners': ['Dummy User'],\n",
    "        'glossary terms': ['active user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'}\n",
    "        },\n",
    "    'dashboard_3' : {\n",
    "        'title': 'dashboard 3',\n",
    "        'description': 'my great dashboard 3',\n",
    "        'charts': ['chart_3'], \n",
    "        'url': 'https://netdata.cloud/', \n",
    "        'platform': dashboard_platform, \n",
    "        'tags': ['failing', 'production'],\n",
    "        'owners': ['Joe Bloggs'],\n",
    "        'glossary terms': ['inactive user'],\n",
    "        'properties': {'foo': 'bar', 'key': 'value'}\n",
    "        },\n",
    "}\n",
    "\n",
    "# make each dashboard\n",
    "for dashboard in dashboards:\n",
    "    \n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dashboard\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dashboard_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=dashboard\n",
    "        ),\n",
    "        aspectName=\"dashboardInfo\",\n",
    "        aspect=models.DashboardInfoClass(\n",
    "            title=dashboards[dashboard].get('title'),\n",
    "            description=dashboards[dashboard].get('description'), \n",
    "            charts=[\n",
    "                builder.make_chart_urn(\n",
    "                    platform=charts[chart].get('platform'), \n",
    "                    name=chart\n",
    "                ) \n",
    "                for chart in dashboards[dashboard].get('charts',[])\n",
    "            ],\n",
    "            lastModified=models.ChangeAuditStampsClass(\n",
    "                created=models.AuditStampClass(\n",
    "                    time=int(time.time()),\n",
    "                    actor=datahub_actor\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dashboards](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dashboards.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to datasets\n",
    "\n",
    "Lets use the tags we defined for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset\n",
    "for dataset in datasets:\n",
    "    \n",
    "    # add tags\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"globalTags\",\n",
    "        aspect=models.GlobalTagsClass(tags=[models.TagAssociationClass(builder.make_tag_urn(tag)) for tag in datasets[dataset].get('tags',[])])\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each chart\n",
    "for chart in charts:\n",
    "    \n",
    "    # add tags\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"chart\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_chart_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=chart,\n",
    "            ),\n",
    "        aspectName=\"globalTags\",\n",
    "        aspect=models.GlobalTagsClass(tags=[models.TagAssociationClass(builder.make_tag_urn(tag)) for tag in charts[chart].get('tags',[])])\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add tags to dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dashboard\n",
    "for dashboard in dashboards:\n",
    "    \n",
    "    # add tags\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dashboard\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dashboard_urn(\n",
    "            platform=dashboards[dashboard].get('platform'), \n",
    "            name=dashboard,\n",
    "            ),\n",
    "        aspectName=\"globalTags\",\n",
    "        aspect=models.GlobalTagsClass(tags=[models.TagAssociationClass(builder.make_tag_urn(tag)) for tag in dashboards[dashboard].get('tags',[])])\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_tags](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_tags.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add owners to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset\n",
    "for dataset in datasets:\n",
    "\n",
    "    # add owners\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"ownership\",\n",
    "        aspect=models.OwnershipClass(\n",
    "            owners=[\n",
    "                models.OwnerClass(builder.make_user_urn(owner), type='DATAOWNER') \n",
    "                for owner in datasets[dataset].get('owners', [])\n",
    "                ]\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add owners to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each chart\n",
    "for chart in charts:\n",
    "\n",
    "    # add owners\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"chart\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_chart_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=chart\n",
    "            ),\n",
    "        aspectName=\"ownership\",\n",
    "        aspect=models.OwnershipClass(\n",
    "            owners=[\n",
    "                models.OwnerClass(builder.make_user_urn(owner), type='DATAOWNER') \n",
    "                for owner in charts[chart].get('owners', [])\n",
    "                ]\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add owners to dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dashboard\n",
    "for dashboard in dashboards:\n",
    "\n",
    "    # add owners\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dashboard\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dashboard_urn(\n",
    "            platform=dashboards[dashboard].get('platform'), \n",
    "            name=dashboard\n",
    "            ),\n",
    "        aspectName=\"ownership\",\n",
    "        aspect=models.OwnershipClass(\n",
    "            owners=[\n",
    "                models.OwnerClass(builder.make_user_urn(owner), type='DATAOWNER') \n",
    "                for owner in dashboards[dashboard].get('owners', [])\n",
    "                ]\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_owners](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_owners.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add glossary terms to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add glossary terms for each dataset\n",
    "for dataset in datasets:\n",
    "\n",
    "    # add glossary terms\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"glossaryTerms\",\n",
    "        aspect=models.GlossaryTermsClass(\n",
    "            terms=[\n",
    "                models.GlossaryTermAssociationClass(f'urn:li:glossaryTerm:{term}') \n",
    "                for term in datasets[dataset].get('glossary terms', [])\n",
    "                ], \n",
    "            auditStamp=models.AuditStampClass(time=int(time.time()), actor=datahub_actor)\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add glossary terms to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add glossary terms for each chart\n",
    "for chart in charts:\n",
    "\n",
    "    # add glossary terms\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"chart\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_chart_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=chart\n",
    "            ),\n",
    "        aspectName=\"glossaryTerms\",\n",
    "        aspect=models.GlossaryTermsClass(\n",
    "            terms=[\n",
    "                models.GlossaryTermAssociationClass(f'urn:li:glossaryTerm:{term}') \n",
    "                for term in charts[chart].get('glossary terms', [])\n",
    "                ], \n",
    "            auditStamp=models.AuditStampClass(time=int(time.time()), actor=datahub_actor)\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add glossary terms to dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add glossary terms for each dashboard\n",
    "for dashboard in dashboards:\n",
    "\n",
    "    # add glossary terms\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dashboard\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dashboard_urn(\n",
    "            platform=dashboards[dashboard].get('platform'), \n",
    "            name=dashboard\n",
    "            ),\n",
    "        aspectName=\"glossaryTerms\",\n",
    "        aspect=models.GlossaryTermsClass(\n",
    "            terms=[\n",
    "                models.GlossaryTermAssociationClass(f'urn:li:glossaryTerm:{term}') \n",
    "                for term in dashboards[dashboard].get('glossary terms', [])\n",
    "                ], \n",
    "            auditStamp=models.AuditStampClass(time=int(time.time()), actor=datahub_actor)\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_glossary_terms](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_glossary_terms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add properties to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each dataset\n",
    "for dataset in datasets:\n",
    "\n",
    "    # add the properties\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"datasetProperties\",\n",
    "        aspect=models.DatasetPropertiesClass(\n",
    "            customProperties=datasets[dataset].get('properties', {})\n",
    "            )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_properties](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_properties.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add upstream lineages to datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"dataset\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_dataset_urn(\n",
    "            platform=datasets[dataset].get('platform'), \n",
    "            name=dataset, \n",
    "            env=datasets[dataset].get('env')\n",
    "            ),\n",
    "        aspectName=\"upstreamLineage\",\n",
    "        aspect=models.UpstreamLineageClass(\n",
    "            upstreams=[\n",
    "                models.UpstreamClass(\n",
    "                    dataset=builder.make_dataset_urn(\n",
    "                        platform=datasets[dataset].get('platform'), \n",
    "                        name=dataset, \n",
    "                        env=datasets[dataset].get('env')\n",
    "                        ), \n",
    "                    type=models.DatasetLineageTypeClass.TRANSFORMED\n",
    "                    ) \n",
    "                for dataset in datasets[dataset].get('upstream datasets', [])\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset_lineage](https://raw.githubusercontent.com/andrewm4894/learn-datahub/main/images/dataset_lineage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add inputs to charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "('Unable to emit metadata to DataHub GMS', {'exceptionClass': 'com.linkedin.restli.server.RestLiServiceException', 'stackTrace': 'com.linkedin.restli.server.RestLiServiceException [HTTP Status:500]: java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:42)\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:50)\\n\\tat com.linkedin.metadata.resources.entity.AspectResource.ingestProposal(AspectResource.java:132)\\n\\tat sun.reflect.GeneratedMethodAccessor55.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat com.linkedin.restli.internal.server.RestLiMethodInvoker.doInvoke(RestLiMethodInvoker.java:172)\\n\\tat com.linkedin.restli.internal.server.RestLiMethodInvoker.invoke(RestLiMethodInvoker.java:326)\\n\\tat com.linkedin.restli.internal.server.filter.FilterChainDispatcherImpl.onRequestSuccess(FilterChainDispatcherImpl.java:47)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.onRequest(RestLiFilterChainIterator.java:86)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.lambda$onRequest$0(RestLiFilterChainIterator.java:73)\\n\\tat java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:670)\\n\\tat java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:683)\\n\\tat java.util.concurrent.CompletableFuture.thenAccept(CompletableFuture.java:2010)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.onRequest(RestLiFilterChainIterator.java:72)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChain.onRequest(RestLiFilterChain.java:55)\\n\\tat com.linkedin.restli.server.BaseRestLiServer.handleResourceRequest(BaseRestLiServer.java:218)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequestWithRestLiResponse(RestRestLiServer.java:242)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequest(RestRestLiServer.java:211)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequest(RestRestLiServer.java:181)\\n\\tat com.linkedin.restli.server.RestRestLiServer.doHandleRequest(RestRestLiServer.java:164)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleRequest(RestRestLiServer.java:120)\\n\\tat com.linkedin.restli.server.RestLiServer.handleRequest(RestLiServer.java:132)\\n\\tat com.linkedin.restli.server.DelegatingTransportDispatcher.handleRestRequest(DelegatingTransportDispatcher.java:70)\\n\\tat com.linkedin.r2.filter.transport.DispatcherRequestFilter.onRestRequest(DispatcherRequestFilter.java:70)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.TimedNextFilter.onRequest(TimedNextFilter.java:55)\\n\\tat com.linkedin.r2.filter.transport.ServerQueryTunnelFilter.onRestRequest(ServerQueryTunnelFilter.java:58)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.TimedNextFilter.onRequest(TimedNextFilter.java:55)\\n\\tat com.linkedin.r2.filter.message.rest.RestFilter.onRestRequest(RestFilter.java:50)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.FilterChainImpl.onRestRequest(FilterChainImpl.java:96)\\n\\tat com.linkedin.r2.filter.transport.FilterChainDispatcher.handleRestRequest(FilterChainDispatcher.java:75)\\n\\tat com.linkedin.r2.util.finalizer.RequestFinalizerDispatcher.handleRestRequest(RequestFinalizerDispatcher.java:61)\\n\\tat com.linkedin.r2.transport.http.server.HttpDispatcher.handleRequest(HttpDispatcher.java:101)\\n\\tat com.linkedin.r2.transport.http.server.AbstractR2Servlet.service(AbstractR2Servlet.java:105)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat com.linkedin.restli.server.spring.ParallelRestliHttpRequestHandler.handleRequest(ParallelRestliHttpRequestHandler.java:63)\\n\\tat org.springframework.web.context.support.HttpRequestHandlerServlet.service(HttpRequestHandlerServlet.java:73)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:852)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:544)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:536)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1581)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1307)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:482)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1549)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1204)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:494)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:374)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:268)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:367)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:918)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart\\n\\tat com.linkedin.metadata.entity.ebean.EbeanEntityService.ingestProposal(EbeanEntityService.java:383)\\n\\tat com.linkedin.metadata.resources.entity.AspectResource.lambda$ingestProposal$3(AspectResource.java:135)\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:30)\\n\\t... 81 more\\n', 'message': 'java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart', 'status': 500})",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.virtualenvs/learn-datahub-dIKgrtBw/lib/python3.8/site-packages/datahub/emitter/rest_emitter.py\u001b[0m in \u001b[0;36m_emit_generic\u001b[0;34m(self, url, payload)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/learn-datahub-dIKgrtBw/lib/python3.8/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    952\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 500 Server Error: Server Error for url: https://netdata.acryl.io/gms/aspects?action=ingestProposal",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3918/1422680221.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m         )\n\u001b[1;32m     24\u001b[0m     )\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0memitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memit_mcp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmcpw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/learn-datahub-dIKgrtBw/lib/python3.8/site-packages/datahub/emitter/rest_emitter.py\u001b[0m in \u001b[0;36memit_mcp\u001b[0;34m(self, mcp)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mpayload\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"proposal\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmcp_obj\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_emit_generic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musageStats\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUsageAggregation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/learn-datahub-dIKgrtBw/lib/python3.8/site-packages/datahub/emitter/rest_emitter.py\u001b[0m in \u001b[0;36m_emit_generic\u001b[0;34m(self, url, payload)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                 raise OperationalError(\n\u001b[0m\u001b[1;32m    189\u001b[0m                     \u001b[0;34m\"Unable to emit metadata to DataHub GMS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 ) from e\n",
      "\u001b[0;31mOperationalError\u001b[0m: ('Unable to emit metadata to DataHub GMS', {'exceptionClass': 'com.linkedin.restli.server.RestLiServiceException', 'stackTrace': 'com.linkedin.restli.server.RestLiServiceException [HTTP Status:500]: java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:42)\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:50)\\n\\tat com.linkedin.metadata.resources.entity.AspectResource.ingestProposal(AspectResource.java:132)\\n\\tat sun.reflect.GeneratedMethodAccessor55.invoke(Unknown Source)\\n\\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\\n\\tat java.lang.reflect.Method.invoke(Method.java:498)\\n\\tat com.linkedin.restli.internal.server.RestLiMethodInvoker.doInvoke(RestLiMethodInvoker.java:172)\\n\\tat com.linkedin.restli.internal.server.RestLiMethodInvoker.invoke(RestLiMethodInvoker.java:326)\\n\\tat com.linkedin.restli.internal.server.filter.FilterChainDispatcherImpl.onRequestSuccess(FilterChainDispatcherImpl.java:47)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.onRequest(RestLiFilterChainIterator.java:86)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.lambda$onRequest$0(RestLiFilterChainIterator.java:73)\\n\\tat java.util.concurrent.CompletableFuture.uniAccept(CompletableFuture.java:670)\\n\\tat java.util.concurrent.CompletableFuture.uniAcceptStage(CompletableFuture.java:683)\\n\\tat java.util.concurrent.CompletableFuture.thenAccept(CompletableFuture.java:2010)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChainIterator.onRequest(RestLiFilterChainIterator.java:72)\\n\\tat com.linkedin.restli.internal.server.filter.RestLiFilterChain.onRequest(RestLiFilterChain.java:55)\\n\\tat com.linkedin.restli.server.BaseRestLiServer.handleResourceRequest(BaseRestLiServer.java:218)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequestWithRestLiResponse(RestRestLiServer.java:242)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequest(RestRestLiServer.java:211)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleResourceRequest(RestRestLiServer.java:181)\\n\\tat com.linkedin.restli.server.RestRestLiServer.doHandleRequest(RestRestLiServer.java:164)\\n\\tat com.linkedin.restli.server.RestRestLiServer.handleRequest(RestRestLiServer.java:120)\\n\\tat com.linkedin.restli.server.RestLiServer.handleRequest(RestLiServer.java:132)\\n\\tat com.linkedin.restli.server.DelegatingTransportDispatcher.handleRestRequest(DelegatingTransportDispatcher.java:70)\\n\\tat com.linkedin.r2.filter.transport.DispatcherRequestFilter.onRestRequest(DispatcherRequestFilter.java:70)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.TimedNextFilter.onRequest(TimedNextFilter.java:55)\\n\\tat com.linkedin.r2.filter.transport.ServerQueryTunnelFilter.onRestRequest(ServerQueryTunnelFilter.java:58)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.TimedNextFilter.onRequest(TimedNextFilter.java:55)\\n\\tat com.linkedin.r2.filter.message.rest.RestFilter.onRestRequest(RestFilter.java:50)\\n\\tat com.linkedin.r2.filter.TimedRestFilter.onRestRequest(TimedRestFilter.java:72)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:146)\\n\\tat com.linkedin.r2.filter.FilterChainIterator$FilterChainRestIterator.doOnRequest(FilterChainIterator.java:132)\\n\\tat com.linkedin.r2.filter.FilterChainIterator.onRequest(FilterChainIterator.java:62)\\n\\tat com.linkedin.r2.filter.FilterChainImpl.onRestRequest(FilterChainImpl.java:96)\\n\\tat com.linkedin.r2.filter.transport.FilterChainDispatcher.handleRestRequest(FilterChainDispatcher.java:75)\\n\\tat com.linkedin.r2.util.finalizer.RequestFinalizerDispatcher.handleRestRequest(RequestFinalizerDispatcher.java:61)\\n\\tat com.linkedin.r2.transport.http.server.HttpDispatcher.handleRequest(HttpDispatcher.java:101)\\n\\tat com.linkedin.r2.transport.http.server.AbstractR2Servlet.service(AbstractR2Servlet.java:105)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat com.linkedin.restli.server.spring.ParallelRestliHttpRequestHandler.handleRequest(ParallelRestliHttpRequestHandler.java:63)\\n\\tat org.springframework.web.context.support.HttpRequestHandlerServlet.service(HttpRequestHandlerServlet.java:73)\\n\\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:790)\\n\\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:852)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:544)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:143)\\n\\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:536)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:235)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:1581)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextHandle(ScopedHandler.java:233)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1307)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:188)\\n\\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:482)\\n\\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:1549)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:186)\\n\\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1204)\\n\\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\\n\\tat org.eclipse.jetty.server.handler.ContextHandlerCollection.handle(ContextHandlerCollection.java:221)\\n\\tat org.eclipse.jetty.server.handler.HandlerCollection.handle(HandlerCollection.java:146)\\n\\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\\n\\tat org.eclipse.jetty.server.Server.handle(Server.java:494)\\n\\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:374)\\n\\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:268)\\n\\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\\n\\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:103)\\n\\tat org.eclipse.jetty.io.ChannelEndPoint$2.run(ChannelEndPoint.java:117)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:336)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:313)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:171)\\n\\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:129)\\n\\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:367)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:782)\\n\\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:918)\\n\\tat java.lang.Thread.run(Thread.java:748)\\nCaused by: java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart\\n\\tat com.linkedin.metadata.entity.ebean.EbeanEntityService.ingestProposal(EbeanEntityService.java:383)\\n\\tat com.linkedin.metadata.resources.entity.AspectResource.lambda$ingestProposal$3(AspectResource.java:135)\\n\\tat com.linkedin.metadata.restli.RestliUtil.toTask(RestliUtil.java:30)\\n\\t... 81 more\\n', 'message': 'java.lang.RuntimeException: Unknown aspect upstreamLineage for entity chart', 'status': 500})"
     ]
    }
   ],
   "source": [
    "for chart in charts:\n",
    "\n",
    "    mcpw = MetadataChangeProposalWrapper(\n",
    "        \"chart\",\n",
    "        models.ChangeTypeClass.UPSERT,\n",
    "        entityUrn=builder.make_chart_urn(\n",
    "            platform=charts[chart].get('platform'), \n",
    "            name=chart\n",
    "            ),\n",
    "        aspectName=\"ChartInfo\",\n",
    "        aspect=models.cha .Inp(\n",
    "            upstreams=[\n",
    "                models.UpstreamClass(\n",
    "                    dataset=builder.make_dataset_urn(\n",
    "                        platform=dataset[dataset].get('platform'), \n",
    "                        name=dataset, \n",
    "                        env=datasets[dataset].get('env')\n",
    "                        ), \n",
    "                    type=models.DatasetLineageTypeClass.TRANSFORMED\n",
    "                    ) \n",
    "                for dataset in charts[chart].get('upstream datasets', [])\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    emitter.emit_mcp(mcp=mcpw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add link to a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a link to dataset\n",
    "#mcpw = MetadataChangeProposalWrapper(\n",
    "#    \"dataset\",\n",
    "#    models.ChangeTypeClass.UPSERT,\n",
    "#    entityUrn=builder.make_dataset_urn(platform=dataset_platform, name=dataset_name, env=datahub_env),\n",
    "#    aspectName=\"addLink\",\n",
    "#    aspect=??? TODO\n",
    "#)\n",
    "#emitter.emit_mcp(mcp=mcpw)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7226eb9ca68a9bc4aea7fee0dd4cb06b718d5ceb7c6196a1d9247977fce61c18"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('learn-datahub-dIKgrtBw': virtualenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
